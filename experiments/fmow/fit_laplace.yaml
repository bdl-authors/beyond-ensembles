---
# Slurm config
name: "SLURM"
partition: "gpu_4"
job-name: "fmow"
num_parallel_jobs: 120
ntasks: 1
cpus-per-task: 8
mem-per-cpu: 4000
time: 600
sbatch_args:
  gres: "gpu:1"
sh_lines:
  - "mkdir -p $TMP/data/wilds"
  - "tar -C $TMP/data/wilds/ -xvzf /pfs/work7/workspace/scratch/so0999-data-ssd/data/wilds/fmow_v1.1.tgz"

---
name: "DEFAULT"
path: "results"
repetitions: 1
reps_per_job: 1
reps_in_parallel: 1

# Train: 76863 datapoints
# Test (OOD): 22108 datapoints

params:
  batch_size: 64
  # data_path: "$TMP/data/"
  data_path: "../../data/"
  use_amp: True
  eval_samples: 1000
  ece_bins: 10
  eval_while_train: True
  disable_wandb: False
  subsample: 0
  test_subsample: 0
  static_bn: True
  seed_offset: 0

---
name: "MultiLaplace"
params:
  model: "laplace_base"
  members: 5
  hessian: "kron"
  base_optimizer:
    lr: 0.0001
    weight_decay: 0.0
